{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a7dc6ee-077c-43bc-935a-7a861cfe8332",
   "metadata": {},
   "source": [
    "# Case Study\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672c47b8-3694-48cc-a4ed-583bcedef106",
   "metadata": {},
   "source": [
    "### Git & version control\n",
    "\n",
    "1. Create a Github repository called \"ames-housing-analysis\".\n",
    "1. Copy the ames.csv data from the `data/` directory into this repository.\n",
    "1. Update the README with a short synopsis of this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0264e8-2b7b-4a83-a83a-66cf5908f585",
   "metadata": {},
   "source": [
    "### Exploratory data analysis\n",
    "\n",
    "1. In the repo create a notebook called `eda.ipynb`.\n",
    "2. Load the ames.csv data.\n",
    "3. Assess the distribution of the response variable (`Sale_Price`).\n",
    "4. How many features are numeric vs. categorical?\n",
    "5. Pick a numeric feature that you believe would be influential on a homes `Sale_Price`. Assess the distribution of the numeric feature. Assess the relationship between that feature and the `Sale_Price`.\n",
    "6. Pick a categorical feature that you believe would be influential on a homes `Sale_Price`. Assess the distribution of the categorical feature. Assess the relationship between that feature and the `Sale_Price`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11285bb6-c072-49bb-96fd-90baf59f7811",
   "metadata": {},
   "source": [
    "### Scikit-learn model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db55b17a-1cb4-4c92-9af4-68ecbffebb6f",
   "metadata": {},
   "source": [
    "Using only the ***numeric features***...\n",
    "\n",
    "1. Split the data into training and test sets. Use 75% of the data for training and 25% for testing.\n",
    "2. Fit a default `sklearn.neighbors.KNeighborsRegressor` model on the training data and score on the test data. Note that scoring on regression models provides the $R^2$.\n",
    "3. Fit a default `sklearn.linear_model.LinearRegression` model on the training data and score on the test data.\n",
    "4. Fit a default `sklearn.ensemble.RandomForestRegressor` model on the training data and score on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7995aeda-064a-4c5f-8a56-e80ee45d405c",
   "metadata": {},
   "source": [
    "### Modular code\n",
    "\n",
    "1. TBD\n",
    "1. TBD\n",
    "1. TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8585bba1-1ba6-44a2-b6c0-214d67cefe2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce20ec7-4b33-4e35-bf72-2f8f794957ca",
   "metadata": {},
   "source": [
    "1. Fill in the blanks to standardize the numeric features and then apply a linear regression model. Does standardizing the numeric features improve the linear regression's $R^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a259df6-0a72-4079-9329-62410c36d959",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import ________\n",
    "\n",
    "lm_model_scaled = make_pipeline(__________, LinearRegression())\n",
    "lm_model_scaled.fit(X_train, y_train)\n",
    "lm_model_scaled.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fdca5e-2302-4a7c-8b90-c45ab5bcc9e0",
   "metadata": {},
   "source": [
    "2. Using the code chunks below, which computes the following:\n",
    "\n",
    "- identifies numeric, categorical, and ordinal columns in our full feature set,\n",
    "- replaces unique values in our ordinal columns (i.e. \"No_basement\", \"No_garage\"), and\n",
    "- creates our encoders for the numeric, categorical, and ordinal columns.\n",
    "\n",
    "<div class=\"admonition note alert alert-info\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Note</b></p>\n",
    "<p class=\"last\">Run the following two code cells without changing anything.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb12410-d8e7-4c2e-b230-a8f70c9ef619",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [],
   "source": [
    "######## RUN THIS CODE CELL AS-IS ########\n",
    "\n",
    "# get columns of interest\n",
    "numerical_columns = num_features.columns\n",
    "ordinal_columns = cat_features.filter(regex='Qual').columns\n",
    "categorical_columns = cat_features.drop(columns=ordinal_columns).columns\n",
    "\n",
    "# replace unique values in our ordinal columns (i.e. \"No_basement\", \"No_garage\") with 'NA'\n",
    "for col in ordinal_columns:\n",
    "    features[col] = features[col].replace(to_replace='No_.*', value='NA', regex=True)\n",
    "    \n",
    "# split full feature set (numeric, categorical, & ordinal features) into train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976253c-06e4-4b7e-a232-b895c30e3d16",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [],
   "source": [
    "######## RUN THIS CODE CELL AS-IS ########\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# create our numeric, categorical, and ordinal preprocessor encoders\n",
    "numerical_preprocessor = StandardScaler()\n",
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "ordinal_categories = [\n",
    "    \"NA\", \"Very_Poor\", \"Poor\", \"Fair\", \"Below_Average\", \"Average\", \"Typical\",\n",
    "    \"Above_Average\", \"Good\", \"Very_Good\", \"Excellent\", \"Very_Excellent\"\n",
    "]\n",
    "list_of_ord_cats = [ordinal_categories for col in ordinal_columns]\n",
    "ordinal_preprocessor = OrdinalEncoder(categories=list_of_ord_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd32cbb-0422-492f-ba2f-578a0932e5d7",
   "metadata": {},
   "source": [
    "2. Continued...\n",
    "\n",
    "Now fill in the blanks to create our `ColumnTransformer` that:\n",
    "\n",
    "- standardizes numerical columns (preprocessor: `numerical_preprocessor`; columns of interest: `numerical_columns`) \n",
    "- one-hot encodes categorical columns (preprocessor: `categorical_preprocessor`; columns of interest: `categorical_columns`) \n",
    "- ordinal encodes ordinal columns (preprocessor: `ordinal_preprocessor`; columns of interest: `ordinal_columns`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228ddff-d016-4bd3-b903-14785d15a527",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('standard_scaler', __________, __________),\n",
    "    ('one_hot_encoder', __________, __________),\n",
    "    ('ordinal_encoder', __________, __________),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f3c190-6b0d-4ffc-905b-dd944695a1d1",
   "metadata": {},
   "source": [
    "3. Now create a pipeline that includes the preprocessing step and applies a linear regression model. Does this improve the linear regression's $R^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ac31e-bbfa-49ce-b603-c3adb3e60614",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [],
   "source": [
    "lm_full = make_pipeline(___________, ___________)\n",
    "_ = lm_full.fit(X_train, y_train)\n",
    "lm_full.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d740df51-8281-4a55-bf5b-d5c544669b91",
   "metadata": {},
   "source": [
    "4. If time allows, create a pipeline that applies these preprocessing steps with a default random forest model and see if performance improves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9469651-6e22-4a2a-a618-d612e50b2b67",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22580e5a-64a2-42fd-8981-0b3feb9b573b",
   "metadata": {},
   "source": [
    "### Model evaluation & selection\n",
    "\n",
    "1. Using same preprocessing pipeline you created in Part 1, fit a default random forest model using a 5-fold cross validation procedure using the root mean squared error metric (`'neg_root_mean_squared_error'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944eeaf8-eba1-4a15-b830-eef4b418b302",
   "metadata": {},
   "source": [
    "2. Run the following two code chunks as is without making any changes. This will create a random forest model pipeline and create specified hyperparameter distributions to draw from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191ab38-5800-44cd-be27-254a34b066ef",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [],
   "source": [
    "######## RUN THIS CODE CELL AS-IS ########\n",
    "\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "\n",
    "class loguniform_int:\n",
    "    \"\"\"Integer valued version of the log-uniform distribution\"\"\"\n",
    "    def __init__(self, a, b):\n",
    "        self._distribution = loguniform(a, b)\n",
    "\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        \"\"\"Random variable sample\"\"\"\n",
    "        return self._distribution.rvs(*args, **kwargs).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076b7d19-5d72-4884-8b51-d074ff1ab99b",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [],
   "source": [
    "######## RUN THIS CODE CELL AS-IS ########\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create preprocessor & modeling pipeline\n",
    "rf = RandomForestRegressor(random_state=123)\n",
    "pipeline = Pipeline([('prep', preprocessor), ('rf', rf)])\n",
    "\n",
    "# specify hyperparameter distributions to randomly sample from\n",
    "param_distributions = {\n",
    "    'rf__n_estimators': loguniform_int(50, 1000),\n",
    "    'rf__max_features': loguniform(.1, .8),\n",
    "    'rf__max_depth': loguniform_int(2, 30),\n",
    "    'rf__min_samples_leaf': loguniform_int(1, 100),\n",
    "    'rf__max_samples': loguniform(.5, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1a024-226e-410c-9cb7-7f184b73d50d",
   "metadata": {},
   "source": [
    "2. Continued...\n",
    "\n",
    "Fill in the blanks to perform a random hyperparameter search based on the following:\n",
    "\n",
    "- use the parameter distributions specified above,\n",
    "- perform 25 random searches,\n",
    "- use a 5-fold cross-validation procedure, and\n",
    "- use root mean squared error (RMSE) as our scoring metric.\n",
    "\n",
    "What are the hyperparameters that provide the lowest RMSE? What is the lowest cross validated RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf06d6b6-8f5f-430e-a38d-c1691922fc02",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import ___________\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, \n",
    "    param_distributions=___________, \n",
    "    n_iter=__,\n",
    "    cv=__, \n",
    "    scoring='___________',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "results = random_search.___________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32ed805-a343-43ba-9ea0-1c10ee56f1bf",
   "metadata": {},
   "source": [
    "### Modular code & unit tests\n",
    "\n",
    "1. TBD\n",
    "1. TBD\n",
    "1. TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6263c5-297d-42e1-9ae8-5fe0cb805781",
   "metadata": {},
   "source": [
    "### ML lifecycle management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661bdd9f-f140-4ee7-959f-b1a8ea60b42e",
   "metadata": {},
   "source": [
    "1. Create and set an MLflow experiment titled \"UC Advanced Python Case Study\"\n",
    "2. Re-perform the random hyperparameter search executed above while logging the hyperparameter search experiment with MLflow's autologging. Title this run \"rf_hyperparameter_tuning\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f92ae-3dd8-4aa9-b52b-8962f9392b08",
   "metadata": {},
   "source": [
    "### Reproducibility with dependency tracking\n",
    "\n",
    "1. TBD\n",
    "1. TBD\n",
    "1. TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081f0d6-2f41-4d23-99f6-d305809f45ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
