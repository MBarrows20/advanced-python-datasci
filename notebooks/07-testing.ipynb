{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd9d2e0d-6b11-454d-a3e4-3e6bdf6af479",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Testing\n",
    "### *and more on modular code*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc36274-6ff4-430d-bd49-a8054cd7625e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- In our coverage of modular code, we talked about abstracting reusable code chunks into their own **functions**\n",
    "    - And, in turn, grouping those functions together into separate **modules**\n",
    "    - We created a function that splits a data set into its features (a DataFrame) and target (a Series)\n",
    "    \n",
    "- In our discussion of feature engineering, we showed how one might make a \"preprocessor\": a column transformer that one-hot encodes categorical features and applies standard scaling to numeric columns\n",
    "    - We then chained this preprocessor together with a logistic regression model in order to form a scikit-learn **pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2874f42-6c62-4228-bee3-952a11414532",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "- We might use the same approach in preprocessing other datasets, so **let's move that logic to its own function and add it to our personal module**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ba661-113d-44e8-8828-0530eba34a34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Writing a Preprocessor Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84276dd0-5d1c-4991-86a3-3d3c6f32f8b5",
   "metadata": {},
   "source": [
    "Sometimes it's easiest to write a function's definition, or *signature*, before actually writing its code.\n",
    "\n",
    "Our function is going to give us a column transformer that we can use in pipelines.\n",
    "The only parameter will be the features DataFrame (at least, for right now)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bfc1a8-4fa8-4b44-adba-518baae1c4f7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "One possible function signature looks like this:\n",
    "\n",
    "```python\n",
    "def make_preprocessor(features):\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65503a5-a248-4f0a-914e-70bb2985143c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Now that we have our defintion, we can add code to it.\n",
    "In this case, we can reuse the code we wrote in the feature engineering section.\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be5273-c16b-4de4-92e1-f1ddf1ca2faa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Can we just put all of that code into our function without any changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92be057e-57d5-405d-91f1-d1419c03e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(features):\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "        ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99da5b7-bc3b-4401-924f-d1f2fe5af86b",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "    <b><p class=\"first admonition-title\" style=\"font-weight: bold;\">Discussion</p></b>\n",
    "    Does anyone see any issues with this?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218afb3f-cf49-4f1c-8fb7-c21367888811",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fake_features = pd.read_csv('../data/planes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb5e1d0-e198-4d47-9dd5-773a56219005",
   "metadata": {
    "tags": [
     "ci-skip"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categorical_preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9w/9m3mzyd96fbdm8q4sy2pjpdw0000gn/T/ipykernel_58616/3965947682.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/9w/9m3mzyd96fbdm8q4sy2pjpdw0000gn/T/ipykernel_58616/2727407406.py\u001b[0m in \u001b[0;36mmake_preprocessor\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     preprocessor = ColumnTransformer([\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m'one-hot-encoder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_preprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m'standard_scaler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_preprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'categorical_preprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "preprocessor = make_preprocessor(fake_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c517343b-3883-49e7-8beb-929c2bcc2a00",
   "metadata": {},
   "source": [
    "Our code is missing some context.\n",
    "`categorical_preprocessor`, `categorical_columns`, `numeric_preprocessor`, and `numeric_columns` aren't defined yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8e82a-3f3d-4ec4-9633-f10b41067760",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Here's an updated version in which we assign to those variables before using them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "405b65a4-fd13-490b-b713-cde9e8243b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(features):\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "    \n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    \n",
    "    numeric_columns = features.select_dtypes(exclude=object)\n",
    "    categorical_columns = features.select_dtypes(include=object)\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "        ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804f7c2e-e468-4886-96f2-f845c60c189b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Things run without error now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9c97464-cb3b-47f1-a721-8e256e1dfda7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = make_preprocessor(fake_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efbec89-5229-437d-abc3-412911d5ff7f",
   "metadata": {},
   "source": [
    "But there are a couple of other issues.\n",
    "\n",
    "What does our resulting preprocessor object look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1cda4d1-0cd3-4c96-abab-6485a80ae77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4a2f7bb-0302-45ff-9686-bdcba63e3ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340778e2-cb1e-4e85-95a3-d9c670842050",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "- We need to remember to *return a value* -- otherwise we can't get anything useful out of the function.\n",
    "\n",
    "- Generally, Python best practice is to import libraries *outside* functions.\n",
    "All imports, even if they're to be used in different functions, are usually placed at the top of the Python module.\n",
    "\n",
    "Let's make those changes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85c223b7-b181-49f8-ad3b-982a3a8b4577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "def make_preprocessor(features):\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    \n",
    "    numeric_columns = fake_features.select_dtypes(exclude=object)\n",
    "    categorical_columns = fake_features.select_dtypes(include=object)\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "        ('standard_scaler', numeric_preprocessor, numeric_columns)\n",
    "    ])\n",
    "    \n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2968aae-f721-4e3b-bd82-848075421116",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "And then make sure it works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78249c2c-e50f-469a-9b40-9037e922cb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                 OneHotEncoder(handle_unknown='ignore'),\n",
       "                                      tailnum                     type                   manufacturer  \\\n",
       "0     N10156  Fixed wing multi engine                        EMBRAER   \n",
       "1     N102UW  Fixed wing multi engine               AIRBUS INDUSTRIE   \n",
       "2     N103US  Fixed wing multi engine               AIRBUS INDUSTRIE   \n",
       "3     N104UW  Fixed wing multi engine               AIRBUS INDUSTRIE   \n",
       "4     N10575  Fixed wing multi engine                        EMBRAER   \n",
       "...      ...                      ...                            ...   \n",
       "3317  N997AT  Fixed wing multi engine...\n",
       "3317    717-200  Turbo-fan  \n",
       "3318      MD-88  Turbo-fan  \n",
       "3319    717-200  Turbo-fan  \n",
       "3320      MD-88  Turbo-jet  \n",
       "3321      MD-88  Turbo-jet  \n",
       "\n",
       "[3322 rows x 5 columns]),\n",
       "                                ('standard_scaler', StandardScaler(),\n",
       "                                         year  engines  seats  speed\n",
       "0     2004.0        2     55    NaN\n",
       "1     1998.0        2    182    NaN\n",
       "2     1999.0        2    182    NaN\n",
       "3     1999.0        2    182    NaN\n",
       "4     2002.0        2     55    NaN\n",
       "...      ...      ...    ...    ...\n",
       "3317  2002.0        2    100    NaN\n",
       "3318  1992.0        2    142    NaN\n",
       "3319  2002.0        2    100    NaN\n",
       "3320  1992.0        2    142    NaN\n",
       "3321  1992.0        2    142    NaN\n",
       "\n",
       "[3322 rows x 4 columns])])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = make_preprocessor(fake_features)\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3655b1f9-63b9-4d3b-b60a-9b779b02d784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.compose._column_transformer.ColumnTransformer"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preprocessor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uc-python",
   "language": "python",
   "name": "uc-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
