{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e38b21-6a98-49fe-a658-169ac7dde1bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ML Lifecycle Management\n",
    "\n",
    "> _\"Hardest Part of ML isn’t ML, it’s Data\"_\n",
    "\n",
    "![Hardest part of ML](images/mlflow_tech_icon.png)\n",
    "\n",
    "[Hidden Technical Debt in Machine Learning Systems](http://papers.neurips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf) (Google NIPS, 2015)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb91cc-22b7-4627-bafb-90ebeb59c539",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "This module is going to introduce you to [MLflow](https://mlflow.org/docs/latest/index.html) for machine learning lifecycle management. We will introduce you to MLflow for... \n",
    "\n",
    "1. managing model experiments,\n",
    "1. tracking hyperparameter tuning,\n",
    "1. registering and serving models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6766f1bf-f670-4b9e-a5d3-16fe7b908d0b",
   "metadata": {},
   "source": [
    "MLflow is a very comprehensive tool so we are just going to touch the surface. However, we will provide you with resources to dig deeper into MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404e626-7f57-41c3-a0f5-e1cb59905502",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "The ML process can be tedious, difficult, and result in lots of technical debt.\n",
    "\n",
    "* How do we ***track***...\n",
    "  - model runs\n",
    "  - hyperparameter experimentations\n",
    "  - performance metrics\n",
    "  \n",
    "* How do we manage ML ***projects*** for...\n",
    "  - reproducibility\n",
    "  - collaboration\n",
    "  \n",
    "* How do we package ML ***models*** for downstream deployment\n",
    "\n",
    "* How do we ***register*** models for managing...\n",
    "  - model lineage\n",
    "  - model versioning\n",
    "  - stage transitions (i.e. dev to stage to prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fde6edc-f728-4fae-ba22-cc60910072aa",
   "metadata": {},
   "source": [
    "## Intro to MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f106ea61-8f8d-4cf6-a502-2be41b5dc963",
   "metadata": {},
   "source": [
    "MLflow is an open source platform designed to manage the complete Machine Learning Lifecycle.\n",
    "\n",
    "![](images/mlflow_capabilities.png)\n",
    "\n",
    "* Used heavily --> 1.7M+ monthly downloads\n",
    "* Well supported --> 170+ contributors & 40 contributing organizations\n",
    "* Well documented\n",
    "   - [mlflow.org](https://mlflow.org/)\n",
    "   - [github.com/mlflow](https://github.com/mlflow)\n",
    "   - [Slack channel](https://join.slack.com/t/mlflow-users/shared_invite/zt-g6qwro5u-odM7pRnZxNX_w56mcsHp8g)\n",
    "   - [stackoverflow.com/questions/tagged/mlflow](https://stackoverflow.com/questions/tagged/mlflow)\n",
    "   - [twitter.com/MLflow](https://twitter.com/MLflow)\n",
    "   - [databricks.com/mlflow](https://databricks.com/product/managed-mlflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed0c49b-bb14-418c-a934-84914da34e07",
   "metadata": {},
   "source": [
    "## Model Tracking\n",
    "\n",
    "Key concepts in tracking:\n",
    "\n",
    "* __Date/time:__ Start and end time of each model run.\n",
    "* __Paramaters:__ Key-value inputs to your code.\n",
    "* __Metrics:__ Numeric values to track how your model’s loss function is converging.\n",
    "* __Artifacts:__ Output files in any format, including models.\n",
    "* __Source:__ what code ran?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808da7c-c995-4221-8729-4aab5d5f52f6",
   "metadata": {},
   "source": [
    "There are several ways to record your modeling experiment:\n",
    "\n",
    "- SQLAlchemy compatible database\n",
    "- remotely to a tracking server\n",
    "- __locally__\n",
    "\n",
    "Let's create an experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f24e2c-910d-433a-9969-03bb497daec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///Users/bradley.boehmke/Desktop/workspace/trainings/advanced-python-datasci/notebooks/mlruns/1', experiment_id='1', lifecycle_stage='active', name='Predicting income', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"Predicting income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88389d78-5056-4472-9122-6c2aa07cd15e",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Tip</b></p>\n",
    "    <p class=\"last\"><tt class=\"docutils literal\">set_experiment</tt> will create and set an experiment if the experiment does not already exist.</p>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7b79a9-d06f-4a88-a7d9-66a5ae3d763f",
   "metadata": {},
   "source": [
    "Note the new local `mlruns/` directory:\n",
    "    \n",
    "![mlruns directory](images/mlruns_directory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4962ecd-0b38-4c0c-a7ce-099b1d6fe035",
   "metadata": {},
   "source": [
    "Before we record a model run let's import and prepare our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b651cf-a27f-49a3-b6f5-f174a6c33316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages used\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# import data\n",
    "adult_census = pd.read_csv('../data/adult-census.csv')\n",
    "\n",
    "# separate feature & target data\n",
    "target = adult_census['class']\n",
    "features = adult_census.drop(columns='class')\n",
    "\n",
    "# drop the duplicated column `\"education-num\"` as stated in the data exploration notebook\n",
    "features = features.drop(columns='education-num')\n",
    "\n",
    "# split into train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=123)\n",
    "\n",
    "# create selector object based on data type\n",
    "numerical_columns_selector = selector(dtype_exclude=object)\n",
    "categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "# get columns of interest\n",
    "numerical_columns = numerical_columns_selector(features)\n",
    "categorical_columns = categorical_columns_selector(features)\n",
    "\n",
    "# preprocessors to handle numeric and categorical features\n",
    "numerical_preprocessor = StandardScaler()\n",
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numerical_preprocessor, numerical_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe6f9f-fe2f-43f3-971a-b02cfa6a1c42",
   "metadata": {},
   "source": [
    "To log a model run we use `start_run()` along with various other logging functions:\n",
    "\n",
    "- `log_param(s)`: to log parameters of interest\n",
    "- `log_metrics(s)`: to log model metrics of interest\n",
    "- `set_tag(s)`: to log decsriptive information (version number, platform ran on, etc.)\n",
    "- `log_artifact(s)`: allows you to log items such as data, models, files, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "267a48fb-f123-46c2-a402-012aff54c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "mlflow.start_run()\n",
    "\n",
    "mlflow.log_param('max_iter', 500)\n",
    "model = make_pipeline(preprocessor, LogisticRegression(max_iter=500))\n",
    "\n",
    "_ = model.fit(X_train, y_train)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "mlflow.log_metric('accuracy', accuracy)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879747c6-109f-4004-a7a0-9f2a0b36bb7b",
   "metadata": {},
   "source": [
    "A more common approach you'll see is to use `start_run()` as a [context manager](https://book.pythontips.com/en/latest/context_managers.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e2859a-44a0-4768-bef6-43bfffe7f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "\n",
    "    mlflow.log_param('max_iter', 500)\n",
    "    model = make_pipeline(preprocessor, LogisticRegression(max_iter=500))\n",
    "\n",
    "    _ = model.fit(X_train, y_train)\n",
    "\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    mlflow.log_metric('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e321aa-511c-4bd5-b7cf-1a01402f29d7",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Question?</b></p>\n",
    "<p class=\"last\">\n",
    "What other useful information could we log?\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b40867-a4d7-4d66-84f7-488f03d9ffd8",
   "metadata": {},
   "source": [
    "The following also logs the model type and the model itself as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48731087-ff2a-4260-a539-b2423b01642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "\n",
    "    mlflow.set_tag('Estimator', 'LogisticRegression')\n",
    "    mlflow.log_param('max_iter', 500)\n",
    "    model = make_pipeline(preprocessor, LogisticRegression(max_iter=500))\n",
    "\n",
    "    _ = model.fit(X_train, y_train)\n",
    "    mlflow.sklearn.log_model(model, 'baseline_model')\n",
    "\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    mlflow.log_metric('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728a826b-d22f-4fa5-bce8-4e1724e3baf6",
   "metadata": {},
   "source": [
    "## MLflow UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b29c75-4a83-4cca-ad64-b3ceea8717fe",
   "metadata": {},
   "source": [
    "We can programmatically retrieve our model run information but MLflow also provides a very nice UI that displays information.\n",
    "\n",
    "- Remove the `#` from the following line of code\n",
    "- Click on the local URL provided\n",
    "\n",
    "![Launch MLflow UI](images/local_url.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70a60c8e-7a36-4cd0-a1f4-bbf3ff66088f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae20967-e258-42bd-862b-3f0d60a9b146",
   "metadata": {},
   "source": [
    "<div class=\"admonition warning alert alert-danger\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Warning</b></p>\n",
    "<p class=\"last\">You'll need to stop the previous code cell when you are done viewing the MLflow UI.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c43af1-761e-42a2-ba47-60b030aca429",
   "metadata": {},
   "source": [
    "## Auto logging\n",
    "\n",
    "MLflow has built-in [auto logging](https://www.mlflow.org/docs/latest/tracking.html#automatic-logging) for many common model libraries:\n",
    "\n",
    "- Scikit-learn\n",
    "- TensorFlow & Keras\n",
    "- XGBoost\n",
    "- Spark ML\n",
    "- Pytorch\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e912618-9268-4f72-8a79-78ceca097ef9",
   "metadata": {},
   "source": [
    "This can simplify our logging.\n",
    "\n",
    "For example, the built in `sklearn.autolog` functionality will automatically log:\n",
    "\n",
    "- Training score obtained by `estimator.score`\n",
    "- Parameters obtained by `estimator.get_params`\n",
    "- Model class name\n",
    "- Fitted estimator as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fcee520-6a5d-48b2-bf32-2f0c94c0e684",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/27 10:02:19 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('columntransformer', ColumnTransformer(transformers=[('one-hot-encoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['workclass', 'education', 'marital-status',\n",
      "                     ...`\n",
      "2021/12/27 10:02:19 WARNING mlflow.utils: Truncated the value of the key `columntransformer`. Truncated value: `ColumnTransformer(transformers=[('one-hot-encoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['workclass', 'education', 'marital-status',\n",
      "                                  'occupatio...`\n",
      "2021/12/27 10:02:19 WARNING mlflow.utils: Truncated the value of the key `columntransformer__transformers`. Truncated value: `[('one-hot-encoder', OneHotEncoder(handle_unknown='ignore'), ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']), ('standard_scaler', StandardScaler(), ['age', 'capital-gain', 'capital-loss'...`\n",
      "2021/12/27 10:02:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/bradley.boehmke/Downloads/ENTER/envs/uc-python/lib/python3.8/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    }
   ],
   "source": [
    "# enable autologging\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    model = make_pipeline(preprocessor, LogisticRegression(max_iter=500))\n",
    "    _ = model.fit(X_train, y_train)\n",
    "\n",
    "    mlflow.log_metric('test_accuracy', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d8d93-4b9c-4ce3-849c-40a26ca9054c",
   "metadata": {},
   "source": [
    "Let's check out this auto-logged run in the UI. You'll notice some additional information logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe17750-67cf-4872-85de-87991d3391fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b27242-501a-4d86-bf44-11f2c36fae69",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52bcbc9-6600-4c64-95b4-d28765dbdc6a",
   "metadata": {},
   "source": [
    "So far, we've just been logging individual runs.\n",
    "\n",
    "However, MLflow makes it easy to track hyperparameter search experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "254d1e42-9653-4b96-8eb5-87e1d38df33d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/27 10:24:33 WARNING mlflow.utils: Truncated the value of the key `estimator`. Truncated value: `Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['wor...`\n",
      "2021/12/27 10:29:22 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/bradley.boehmke/Downloads/ENTER/envs/uc-python/lib/python3.8/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2021/12/27 10:29:24 INFO mlflow.sklearn.utils: Logging the 5 best runs, no runs will be omitted.\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', ColumnTransformer(transformers=[('one-hot-encoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['workclass', 'education', 'marital-status',\n",
      "                          ...`\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `preprocessor`. Truncated value: `ColumnTransformer(transformers=[('one-hot-encoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['workclass', 'education', 'marital-status',\n",
      "                                  'occupatio...`\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `preprocessor__transformers`. Truncated value: `[('one-hot-encoder', OneHotEncoder(handle_unknown='ignore'), ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']), ('standard_scaler', StandardScaler(), ['age', 'capital-gain', 'capital-loss'...`\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', ColumnTransformer(transformers=[('one-hot-encoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['workclass', 'education', 'marital-status',\n",
      "                          ...`\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `preprocessor`. Truncated value: `ColumnTransformer(transformers=[('one-hot-encoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['workclass', 'education', 'marital-status',\n",
      "                                  'occupatio...`\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `preprocessor__transformers`. Truncated value: `[('one-hot-encoder', OneHotEncoder(handle_unknown='ignore'), ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']), ('standard_scaler', StandardScaler(), ['age', 'capital-gain', 'capital-loss'...`\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', ColumnTransformer(transformers=[('one-hot-encoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['workclass', 'education', 'marital-status',\n",
      "                          ...`\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `preprocessor`. Truncated value: `ColumnTransformer(transformers=[('one-hot-encoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['workclass', 'education', 'marital-status',\n",
      "                                  'occupatio...`\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `preprocessor__transformers`. Truncated value: `[('one-hot-encoder', OneHotEncoder(handle_unknown='ignore'), ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']), ('standard_scaler', StandardScaler(), ['age', 'capital-gain', 'capital-loss'...`\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', ColumnTransformer(transformers=[('one-hot-encoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['workclass', 'education', 'marital-status',\n",
      "                          ...`\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `preprocessor`. Truncated value: `ColumnTransformer(transformers=[('one-hot-encoder',\n",
      "                                 OneHotEncoder(handle_unknown='ignore'),\n",
      "                                 ['workclass', 'education', 'marital-status',\n",
      "                                  'occupatio...`\n",
      "2021/12/27 10:29:24 WARNING mlflow.utils: Truncated the value of the key `preprocessor__transformers`. Truncated value: `[('one-hot-encoder', OneHotEncoder(handle_unknown='ignore'), ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']), ('standard_scaler', StandardScaler(), ['age', 'capital-gain', 'capital-loss'...`\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# basic model object\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Create grid of hyperparameter values\n",
    "hyper_grid = {'knn__n_neighbors': [5, 10, 15, 20]}\n",
    "\n",
    "# create preprocessor & modeling pipeline\n",
    "pipeline = Pipeline([('preprocessor', preprocessor), ('knn', knn)])\n",
    "\n",
    "# enable autologging\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # Tune a knn model using grid search\n",
    "    grid_search = GridSearchCV(pipeline, hyper_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    results = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3ea08-abad-4e43-adf9-94a68890e3fe",
   "metadata": {},
   "source": [
    "If we look at the MLflow UI we'll notice that autologging a parameter search results in a single parent run and nested child runs, which contains:\n",
    "\n",
    "* Parent\n",
    "   - Training score\n",
    "   - Best parameter combination\n",
    "   - Fitted best estimator\n",
    "   - and more\n",
    "* Child\n",
    "   - CV test score for each parameter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c6f446c-7a31-4c92-a9ef-8644aa50cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea0586-994a-4d6a-961e-e5b3ecd30e40",
   "metadata": {},
   "source": [
    "## Registering models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b6665-e919-469b-ab3d-515dc208a219",
   "metadata": {},
   "source": [
    "MLflow provides a ___Model Registry___ that provides a centralized and collaborative approach to model lifecycle management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5795b9-f932-4d77-9121-fe8f7ca4f72a",
   "metadata": {},
   "source": [
    "__One Collaborative Hub__: The Model Registry provides a central hub for making models discoverable, improving collaboration and knowledge sharing across the organization.\n",
    "\n",
    "![](images/registered_models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff806eb-3a1a-45bc-87f3-02c23f4606ba",
   "metadata": {},
   "source": [
    "__Manage the entire Model Lifecycle (MLOps)__: The Model Registry provides lifecycle management for models from experimentation to deployment, improving reliability and robustness of the model deployment process.\n",
    "\n",
    "1. Overview of active model versions and their deployment stage\n",
    "2. Request/Approval workflow for transitioning deployment stages\n",
    "\n",
    "![](images/model_registry_mlops.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf98c9-ff61-45ec-9f7e-1b0669c12498",
   "metadata": {},
   "source": [
    "__Visibility and Governance__: The Model Registry provides full visibility into the deployment stage of all models, who requested and approved changes, allowing for full governance and auditability.\n",
    "\n",
    "1. Full activity log of stage transition requests, approvals, etc.\n",
    "\n",
    "![](images/model_registry_visibility.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a0a14-eb18-4cb8-abc9-2285b459f080",
   "metadata": {},
   "source": [
    "Full provenance from Model marked production in the Registry to ...\n",
    "1. Run that produced the model\n",
    "2. Notebook that produced the run\n",
    "3. Exact revision history of the notebook that produced the run\n",
    "\n",
    "![](images/model_registry_governance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e3812d-dbcf-4967-9d72-dd0ce5dfce79",
   "metadata": {},
   "source": [
    "Let's go ahead and register a model\n",
    "\n",
    "<div class=\"admonition note alert alert-info\">\n",
    "    <p class=\"first admonition-title\" style=\"font-weight: bold;\"><b>Note</b></p>\n",
    "<p class=\"last\">Although in this example we register a model via the MLflow UI, we can also register a model programmatically.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0372d466-7345-4855-b89d-1831d0a3ab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-12-28 15:47:56 -0500] [56706] [INFO] Starting gunicorn 20.1.0\n",
      "[2021-12-28 15:47:56 -0500] [56706] [INFO] Listening at: http://127.0.0.1:5000 (56706)\n",
      "[2021-12-28 15:47:56 -0500] [56706] [INFO] Using worker: sync\n",
      "[2021-12-28 15:47:56 -0500] [56708] [INFO] Booting worker with pid: 56708\n",
      "[2021-12-28 15:47:56 -0500] [56709] [INFO] Booting worker with pid: 56709\n",
      "[2021-12-28 15:47:56 -0500] [56710] [INFO] Booting worker with pid: 56710\n",
      "[2021-12-28 15:47:56 -0500] [56711] [INFO] Booting worker with pid: 56711\n",
      "^C\n",
      "[2021-12-28 15:48:35 -0500] [56706] [INFO] Handling signal: int\n",
      "[2021-12-28 15:48:35 -0500] [56711] [INFO] Worker exiting (pid: 56711)\n"
     ]
    }
   ],
   "source": [
    "!mlflow server \\\n",
    "    --backend-store-uri sqlite:///mlflow.db \\\n",
    "    --default-artifact-root ./artifacts \\\n",
    "    --host 127.0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49764e7-a70c-42eb-a116-c3b3188fe88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_server_uri = \"http://127.0.0.1:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d3c3db-8c0d-490b-83a5-317789040d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-12-28 15:49:14 -0500] [56857] [INFO] Starting gunicorn 20.1.0\n",
      "[2021-12-28 15:49:14 -0500] [56857] [INFO] Listening at: http://127.0.0.1:5000 (56857)\n",
      "[2021-12-28 15:49:14 -0500] [56857] [INFO] Using worker: sync\n",
      "[2021-12-28 15:49:14 -0500] [56860] [INFO] Booting worker with pid: 56860\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56363e-6ec2-4131-9b29-8f51fe506c32",
   "metadata": {},
   "source": [
    "## Wrapping up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc797fd-850d-4a11-b215-c5d6ea49d646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
